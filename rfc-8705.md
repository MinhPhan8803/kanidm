# RFC 8705

## Overview
RFC 8705 specifies authentication options for OAuth2 based on mutual TLS using client certificates. Such a certificate is associated with a private key, which (and only which) can be used to access protected resources. Therefore, outside parties cannot access these resources even if they got hold of the tokens.

## Mutual TLS method
The definition includes 2 ways to use client certificates for authentication: PKI (public key infrastructure) in which the server uses a certificate chain and a single subject name for authentication; or Self Signed Certificate in which a list or source of certificates (registered beforehand) is used for validation by checking if the client owns the associated private keys.

This proposal suggests the latter method is used, with a certificate source as defined by RFC7591 as this provides more flexibility on the client side (rotating certificates without having to register with the server).

An example workflow would look like this:

1. New client registers their certificate source with the server.
2. During authentication, client presents a certificate to the server.
3. Server checks the source for the presented certificate.
4. TLS used to check if client posesses the corresponding private key.
5. If (3) and (4) matches, auth is successful and access token is issued.

## Access tokens
Here is the fun part, the access token can be associated with the certificate after auth is successful, this association should be accessible by the protected resource. This will require a policy such that mutual TLS is always used for all resources all for all clients of some type.

The workflow:
1. The client sends access token to resource, this include a binding to a certificate.
2. The resource checks if the certificate associated with this token matches the certificate used for mutual TLS.
3. If match, provides resource. If not, returns 401.

The definition also provides 2 example methods for this association. This proposal suggests embedding the certificate hash in a JSON Web Token since it is already used by Kanidm.

## Certificate authority
There are 2 possible approaches for the source of certificates: Have a built in CA for Kanidm, or have admins supply their own. This proposal suggests the inclusion of both approaches.

## The implementation
Now onto another (less) fun part.
Notable crates used:
- `openssl`, specifically the `openssl::x509` module.
- `tokio-rustls`
- More as implementation details are worked out.

### The CA
- For Kanidm's own CA, we can use `openssl::x509` to generate certificates. These can then be stored as byte strings in the database, or have a dedicated tables with specific columns for easier parsing. Here we can query the database directly

- For external systems, we will have a list of supported systems, which the admins can supply policies for. We will use a `rustls` client to connect to these systems and query the certificates.

- There will be a common module for handling certificates, that will switch between Kanidm's own CA and external systems, depending on a config file.

### Authentication
- We will build on the existing server to also handle requests that include certificates.
- The server will interact with the aforementioned CA module to check if certificate exists.
- A `rustls` server will also be used to receive the incoming private key.
- During this process we will need to signify that this client uses mutual TLS to all HTTP resources, and this client is using a specific certificate. This can be achieved by once again using the database. We also have to partially rewrite HTTP resources to account for this configuration.

### The HTTP resources
- First they check with the mentioned database if this client used mutual TLS, if so obtain the certificate.
- If mutual TLS is used, after a hash is obtained they will attempt to communicate with the CA module to check if a certificate matches this hash. They will then compare the certificates, if failure return 401.

Caveat: 
- Should try to minimize database reads where possible to reduce latency.
- [This hackernews thread](https://news.ycombinator.com/item?id=24857145) describes RFC 8705 as generally bad to implement, so, fun stuff.

# DPOP

## Overview
Oauth2 DPoP defines an alternate to RFC 8705 by essentially pairing a Demonstration of Proof Of Posession header in a request. In effect this achieves the same thing as RFC 8705 - preventing outside parties who hold the access tokens from accessing resources.

## The method
At a high level, this works by binding a public key to the issued access token when the client first asks for authorization. Then, when the client tries to access resources it will need to demonstrate posession of the private key (hence the name) by sending the public key along with the access token. A DPoP header (in the form of a JWT) will be the medium through which the client presents its key.

## Considerations
- We need a way for the server to signal to resources that client opts to use DPoP. This means that a storage mechanism is needed, potentially through server session.
- The documentation requires a DPoP to only be valid for a short limited time to prevent parties who got hold of it from trying to use it. This means a timeout mechanism is needed.
- Attackers may opt to pre generate DPoP proofs ahead of time. The document suggests preventing this by having the server includes a Nonce header in the HTTP response.
- For the resources, checking if a client is using DPoP can prove tricky, depending on the method used to embed the proof in the token.
- Needs to document the methods of requesting to use DPoP proves, and how to embed the proves in the access token.
- The tests would also be quite involved, since we need to throughly test the (quite complicated) requests, the Nonce header, and the timer.

## The implementation

### The ideas
- First we need a separate module to handle DPoP authentication alongside the bearer scheme.
- When the server parses the request for authorization, it needs to check if the client is asking to use DPoP, if yes performs binding. This binding could be in the form of a database entry, stored in the session if applicable since this binding will be short lived. 
- The server will also need to randomly generate a Nonce header for the response. Finally, the binding will need to be destroyed after a period of time, again a session might be useful here.
- When resources parses request, it will also check if client has a DPoP header. This time, if DPoP is used it will need to query the database/session to see if the proves match.
- Overall the idea seems pretty simple, the actual implementation might be tricky since there are lots of fine details involved.

### The crab
- There might not be any new crates needed, with existing crates (for decoding, serder, and HTTP server) looking sufficient.
- We might also look at writing this in Axum right away ahead of the eventual server rewrite.